\section{Cel pracy}
Celem niniejszej pracy magisterskiej jest zbadanie wpływu różnych zabiegów
stosowanych w~splotowych sieciach neuronowych na~jakość działania owych sieci.
W~pracy skupiono się~wyłącznie na~aspektach dotyczących jakości klasyfikacji,
w~szczególności~na~dokładności (\textit{ang.~accuracy}). Aspekty dotyczące złożoności
obliczeniowej oraz złożoności pamięciowej celowo zostały pominięte w~pracy.

\section{Historia uczenia maszynowego}
W znakomitej większości przypadków tworzenie programu komputerowego polega
na podaniu ciągu instrukcji, które mają zostać wykonane, aby rozwiązać zadany
problem. Co~jednak, jeśli nie wiadomo, w jaki sposób osiągnąć zamierzony cel?

W 1956 roku Arthur Samuel postanowił napisać program komputerowy
potrafiący grać w~warcaby lepiej niż jego autor. Stworzył więc aplikację,
która grała sama ze~sobą, ucząc się na własnych błędach i sukcesach.
Z czasem oprogramowanie stawało się coraz to lepsze. W 1962 roku program był
na~tyle dobry, że pokonał mistrza stanu Connecticut: Roberta Nealey'ego
(obecnie istnieje algorytm, z którym nie da się wygrać w warcaby).

Z~czasem uczenie maszynowe powoli zyskiwało na~zainteresowaniu.
Wiele tworzonych mechanizmów było inspirowanych naturą (np. algorytmy
ewolucyjne czy sztuczne sieci neuronowe). Jednak dużym ograniczeniem
w~większości problemów wciąż pozostawała konieczność nadzorowania procesu
uczenia, tzn. dla~każdego zbioru wejściowego należało podać spodziewany wynik
(np. przy rozpoznawaniu cyfr podawano rzeczywistą cyfrę odpowiadającą podanemu
obrazkowi).

W 1986 roku opracowano teoretyczny model mechanizmu potrafiącego stwierdzać
podobieństwo różnych danych i uczyć się bez nadzoru. Była to tzw.~Maszyna
Boltzmanna. Potrafiła ona zauważać cechy charakterystyczne dla~różnego typu
danych (np. w problemie rozpoznawania cyfr zauważała charakterystyczne łuki,
które odróżniały jedne znaki od drugich).
Nie istniał jednak żaden efektywny sposób uczenia mechanizmu.
Dopiero w połowie pierwszej dekady XXI wieku zaczęły powstawać pierwsze szybkie
algorytmy uczące. Wówczas rozwój dziedziny znacznie przyspieszył.
Szczególne zainteresowanie zyskało podejście zwane głębokim uczeniem.

\section{Zastosowania}
Głębokie uczenie (\textit{ang. deep learning}), zwane również uczeniem
o~głębokich strukturach (\textit{ang. deep structured learning}) lub uczeniem
hierarchicznym (\textit{ang. hierarchical learning}), to~koncepcja uczenia
polegająca na~tworzeniu modelu danych o wielu warstwach, gdzie każda kolejna
warstwa reprezentuje wyższy poziom abstrakcji niż poprzednia (warstwa wejściowa
ma~poziom najniższy). Przykładowo dla warstwowej sieci neuronowej rozpoznającej
twarze, w~pierwszej warstwie ukrytej zauważane są~najprostsze cechy (np. łuki,
krawędzie), w kolejnych warstwach rozpoznawane są coraz to~większe fragmenty
obrazka, by~w~warstwie wyjściowej uzyskać rozpoznanie całej twarzy.

Obecnie podejście to~jest z~powodzeniem wykorzystywane w~takich usługach jak:
\begin{itemize}
  \item Google Search by Image,
  \item Google Voice Search,
  \item Google Now,
  \item Siri,
  \item S Voice,
  \item Amazon Recommendations,
  \item Google Self-Driving Car.
\end{itemize}

Szczególnie dużo projektów wykorzystujących głębokie uczenie prowadzi firma
Google (w ramach projektu Google Brain). Między innymi jednym z~problemów,
którym się~zajmowała było oznaczanie na~mapie adresów budynków na~podstawie
obrazów z~systemu Google Street View. Choć~najpierw rozpoznawaniem zajmowali
się~ludzie, to~na początku 2014 roku stworzono system, który
samodzielnie potrafił rozpoznawać adresy. Robił to~znacznie szybciej niż ludzie
(adresy wszystkich budynków we~Francji rozpoznał w niespełna godzinę),
a~przy~tym~popełniał mniej błędów.

W~ramach badań nad~głębokim uczeniem, w~obrębie projektu Microsoft Research,
powstał tłumacz potrafiący w~czasie rzeczywistym tłumaczyć przemówienia
wygłaszane w~języku angielskim na~język chiński, korzystając z~głosu
osoby mówiącej. Innym znacznym osiągnięciem w~dziedzinie przetwarzania języka naturalnego (\textit{ang.
Natural Language Processing, NLP}) był system stworzony przez~IBM: Watson.
Głównym celem systemu było odpowiadanie na~pytania zadawane w~języku naturalnym.
W~2011 roku Watson wziął udział w~amerykańskim teleturnieju \textit{Jeopardy!} (polskim odpowiednikiem był
teleturniej \textit{Va Banque}). Gra polegała na~odpowiadaniu na~pytania z~różnych dziedzin, a~za~każdą
prawidłową odpowiedź gracz otrzymywał punkty. Watson był tak dobry, że~pokonał najlepszych graczy i~wygrał
milion dolarów.

Choć rozpoznawanie obrazów było niegdyś dziedziną, w~której komputery wypadały
znacznie gorzej niż~ludzie, to~wraz z~rozwojem głębokiego uczenia sytuacja
uległa zmianie. Już w~2011 roku podczas konferencji IJCNN (International Joint
Conference on Neural Networks) komputery poradziły sobie z~problemem
rozpoznawania znaków drogowych lepiej od ludzi (dwukrotnie lepiej).

Kolejnym przełomem w~rozpoznawaniu obrazów był~system stworzony w~ramach
Microsoft Research w lutym 2015 roku, którego zadaniem było stwierdzenie,
co~znajduje się~na~obrazku, a~następnie przypisanie mu odpowiedniej kategorii spośród
ponad 100000 dostępnych. Okazało się, że~ludzie średnio popełniali 5.1\% błędów,
a~algorytm Microsoftu: 4.94\%.

Inne zastosowania głębokiego uczenia jakie są badane to m.in:
\begin{itemize}
  \item rozpoznawanie niechcianych wiadomości (tzw. spamu),
  \item automatyczne generowanie opisów dla obrazków w~języku naturalnym (\cite{img-desc-generator}),
  \item rozpoznawanie zmian nowotworowych,
  \item opracowywanie nowych leków,
  \item rozpoznawanie emocji (\textit{ang. affective computing}).
\end{itemize}
